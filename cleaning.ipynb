{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b124b40d-ea76-4c38-adaa-aee705694891",
   "metadata": {},
   "source": [
    "### This notebook is not directly used in the application. Indeed, it is only used to fill the \"wave\" folder with a unique dataset for each wave (i.e: all stata files merged together). We use directly the files created by this notebook. \n",
    "\n",
    "<br>\n",
    "\n",
    "> `open_wave(wave_index)` : opens all files from a given wave and returns a list of all the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "188e25ff-b87f-4fa4-9d1a-2e9e5dcf21c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "\n",
    "def open_wave(wave, path):\n",
    "    \n",
    "    PATH = f\"{path}rawdata/wave{str(wave)}\"\n",
    "    dfList = []\n",
    "    \n",
    "    #iterate over all files that end with \".dta\" and add them to a dfList\n",
    "    for index, dirs, files in os.walk(PATH):\n",
    "        for file in files:\n",
    "            if file.endswith(\".dta\"):\n",
    "                df = pd.read_stata(\n",
    "                    os.path.join(index, file),\n",
    "                    chunksize=1,\n",
    "                    convert_categoricals=False).read()\n",
    "                \n",
    "                #add the current df to the list\n",
    "                dfList.append(df)\n",
    "            \n",
    "    return dfList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7990bb5d-6b72-4b57-83a9-91d69cafff71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of wave 1: (30419, 1649)\n",
      "The file of wave 1 has been saved!\n",
      "\n",
      "Shape of wave 2: (37143, 1897)\n",
      "The file of wave 2 has been saved!\n",
      "\n",
      "Shape of wave 3: (28463, 3008)\n",
      "The file of wave 3 has been saved!\n",
      "\n",
      "Shape of wave 4: (58000, 2475)\n",
      "The file of wave 4 has been saved!\n",
      "\n",
      "Shape of wave 5: (66065, 3059)\n",
      "The file of wave 5 has been saved!\n",
      "\n",
      "Shape of wave 6: (68085, 4193)\n",
      "The file of wave 6 has been saved!\n",
      "\n",
      "Shape of wave 7: (77202, 6562)\n",
      "The file of wave 7 has been saved!\n",
      "\n",
      "Shape of wave 8: (46733, 4298)\n",
      "The file of wave 8 has been saved!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#merge and save all data into 1 df per wave\n",
    "path = \"/Users/josephbarbier/Desktop/PROJETpython/\"\n",
    "for i in range(1,9):\n",
    "    \n",
    "    #merge all dfs into one df\n",
    "    data = reduce(lambda left, right:\n",
    "                  pd.merge(left,\n",
    "                           right,\n",
    "                           on = [\"mergeid\"],\n",
    "                           how = \"outer\",\n",
    "                           suffixes = (None, \"_y2\")),\n",
    "                    open_wave(i, path=path))\n",
    "    \n",
    "    #all wave 3 variables start with \"sl_\" (for SHARE LIFE) and we remove them\n",
    "    #because otherwise our regex functions don't work\n",
    "    if i==3:\n",
    "        data.columns = data.columns.str.replace(r'^sl_', '', regex=True)\n",
    "\n",
    "    #remove columns containing the \"_y2\" pattern since they are dupplicate\n",
    "    data = data[data.columns.drop(list(data.filter(regex='_y2$')))]\n",
    "    print(f\"Shape of wave {i}:\", data.shape)\n",
    "    data.to_csv(f\"wave/wave{i}\", index=False)\n",
    "    print(f\"The file of wave {i} has been saved!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aadfcc-def3-469d-b369-30b2bfafd3fc",
   "metadata": {},
   "source": [
    "> `compute_stats(dataframe, wave)` : calculates mean, median and standard deviation for all quantitative variables for a given wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "00ca4142-c62c-403c-8b0c-ec9dc2ec5b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "##compute and save all results\n",
    "#for wave in tqdm(range(1,9)):\n",
    "#    \n",
    "#    #open data\n",
    "#    data = pd.read_csv(f\"wave{wave}.csv\", low_memory=False)\n",
    "#    print(data.shape)\n",
    "#\n",
    "#    #apply compute_stats function\n",
    "#    test = data.copy()\n",
    "#    stats = compute_stats(test, wave=wave)\n",
    "#    \n",
    "#    #save results\n",
    "#    stats.to_csv(f\"stats_wave{wave}.csv\", index=False)\n",
    "#    stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "62bba1ea-6f03-48b6-8974-d5e33bccea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_stats = pd.Series(dtype=np.float64)\n",
    "##check shape of all stats\n",
    "#for wave in tqdm(range(1,9)):\n",
    "#    data = pd.read_csv(f\"stats_wave{wave}.csv\", low_memory=False)\n",
    "#    #print(f\"Descriptive stats of wave{wave} \\n\", data.head(), \"\\n\")\n",
    "#    all_stats = pd.concat([all_stats, data])\n",
    "#\n",
    "#print(all_stats.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
